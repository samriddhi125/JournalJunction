The literature review on visual speech recognition comprises of various methodologies and datasets, which highlights both advancements and limitations in this application of Computer Vision. From custom datasets to well known datasets like GRID Corpus, diverse approaches such as CNNs, LSTMs, and attention mechanisms have been applied to achieve optimistic accuracies. While certain models exhibit superior performance, like CNN-HMM achieving 80% accuracy, challenges continue, such as very less dataset diversity and inability to identify past  information. LipNet which is the first end-to-end sentence level lip reading model with accuracy of 95.2% on GRID corpus. The limitation of LipNet was that the sentences were similar to eachother and following same pattern, making it easier to predict. These findings are particularly relevant for lipreading in Hindi using machine learning, offering insights into using facial features for communication in noisy or audio-inaccessible environments or having conversation with people with hearing impairments, despite existing challenges.